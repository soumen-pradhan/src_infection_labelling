{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from urllib.request import urlopen\n","from io import BytesIO\n","from zipfile import ZipFile\n","from matplotlib.pyplot import xlabel\n","import networkx as nx\n","from GMLA_2 import *\n","from PTVA_algo_final2 import *\n","from TSSI_complete import *"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["G_football, _ = load(\"football\")\n","G_football.nodes()"]},{"cell_type":"markdown","metadata":{},"source":["with open(\"facebook.csv\", \"r\") as data:<br>\n","    next(data, None)<br>\n","    G_facebook = nx.parse_edgelist(<br>\n","        data, delimiter=\",\", create_using=nx.Graph, nodetype=int<br>\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["d_url = \"http://www-personal.umich.edu/~mejn/netdata/dolphins.zip\"\n","with urlopen(d_url) as sock, ZipFile(BytesIO(sock.read())) as zf:\n","    gml = zf.read(\"dolphins.gml\").decode().split(\"\\n\")[1:]\n","    G_dolphin = nx.parse_gml(gml)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["adj_noun = nx.read_gml(\"adjnoun.gml\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" # Counter -> dict {item: freq}\n","from collections import Counter, defaultdict"]},{"cell_type":"markdown","metadata":{},"source":["or Algorithms using Partial Infection - GFHF, LGC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gen_data_partial(algo, dataset, n_snaps=10):\n","    df_dist_err = defaultdict(list)\n","    df_time = defaultdict(list)\n","    err_freq = []\n","    for G_name, G in dataset.items():\n","        src = rand.choice(list(G.nodes()))\n","        N = G.number_of_nodes()\n","        known_dicts = simulatePartialInfection(\n","            G, src, threshold=0.3, sampling=0.2, n_snaps=n_snaps\n","        )\n","        score_time = [\n","            [alg(G, label, src) for label in known_dicts] for alg in algo.values()\n","        ]\n","        \"\"\"\n","        alg_data = [alg1 [], alg2 [] ...]\n","        alg1 [] -> [(dist_err), (snapshot_time)]\n","        snapshot_score_dict = {node: score}\n","        \"\"\"\n","        alg_data = [list(zip(*res)) for res in score_time]\n","        \n","        dict_freq = defaultdict(list)\n","        \n","        freq_hops = [Counter(err) for err, _ in alg_data]\n","        avg_dist_err = [stats.mean(err) for err, _ in alg_data]\n","        avg_time = [stats.mean(time) for _, time in alg_data]\n","        for alg_name, de, time, freq in zip(algo.keys(), avg_dist_err, avg_time, freq_hops):\n","            df_dist_err[alg_name].append(de)\n","            df_time[alg_name].append(time)\n","            dict_freq[alg_name] = [freq[i] if i in freq else 0 for i in range(4)]\n","        \n","        df = pd.DataFrame(dict_freq, columns=algo.keys(), index=list(range(4)))\n","        err_freq.append(df)\n","    \n","    df_de = pd.DataFrame(df_dist_err, columns=algo.keys(), index=dataset.keys())\n","    df_time = pd.DataFrame(df_time, columns=algo.keys(), index=dataset.keys())\n","                        \n","    return df_de, df_time, err_freq\n","    "]},{"cell_type":"markdown","metadata":{},"source":["or Algorithms using Complete Observation - GMLA, PTVA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gen_data_complete(algo, dataset, iterations):\n","    df_dist_err = defaultdict(list)\n","    df_time = defaultdict(list)\n","    err_freq = []\n","    for G_name, G in dataset.items():\n","        N = G.number_of_nodes()\n","        score_time = [alg(G, G_name, iterations) for alg in algo.values()]\n","        alg_data = [list(zip(*res)) for res in score_time]\n","        dict_freq = defaultdict(list)\n","        freq_hops = [Counter(err) for err, _ in alg_data]\n","        avg_dist_err = [stats.mean(err) for err, _ in alg_data]\n","        avg_time = [stats.mean(time) for _, time in alg_data]\n","        for alg_name, de, time, freq in zip(\n","            algo.keys(), avg_dist_err, avg_time, freq_hops\n","        ):\n","            df_dist_err[alg_name].append(de)\n","            df_time[alg_name].append(time)\n","            dict_freq[alg_name] = [freq[i] if i in freq else 0 for i in range(4)]\n","        df = pd.DataFrame(dict_freq, columns=algo.keys(), index=list(range(4)))\n","        err_freq.append(df)\n","    df_de = pd.DataFrame(df_dist_err, columns=algo.keys(), index=dataset.keys())\n","    df_time = pd.DataFrame(df_time, columns=algo.keys(), index=dataset.keys())\n","    return df_de, df_time, err_freq\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Datasets and algorithms"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["comp_algo = {\"GMLA\": GMLA, \"PTVA\": PTVA_algo}\n","par_algo = {\"GFHF\": TSSI_GFHF, \"LGC\": TSSI_LGC}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = {\n","        # \"Karate\": nx.karate_club_graph(),\n","        \"Football\": G_football,\n","        # \"Facebook\": G_facebook,\n","        # \"Dolphin\": G_dolphin,\n","        # \"albert barabasi\": nx.barabasi_albert_graph(n=100, m=5),\n","        # \"erdos renyi\": nx.erdos_renyi_graph(n=100, p=0.2),\n","        # \"Adjective Noun\": adj_noun\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["de_comp, time_comp, freq_comp = gen_data_complete(comp_algo, dataset, 30)\n","de_par, time_par, err_freq_par = gen_data_partial(par_algo, dataset, 30)"]},{"cell_type":"markdown","metadata":{},"source":["Plotting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["de = pd.concat([de_par, de_comp], axis=1)\n","de.plot.bar(title=\"Distance Error\", xlabel=\"Datasets\", ylabel=\"distance error\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["time = pd.concat([time_par, time_comp], axis=1)\n","time.plot.bar(title=\"Time of execution\", xlabel=\"Datasets\", ylabel=\"time (in ms)\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["freq = [pd.concat([p, c], axis=1) for p, c in zip(err_freq_par, freq_comp)]\n","for f, title in zip(freq, dataset.keys()):\n","    f.plot.bar(title=title, xlabel=\"Number of hops\", ylabel=\"frequency\")\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}
